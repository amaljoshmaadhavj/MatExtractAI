# MatExtractAI

> **AI-powered Extraction & Validation of Materials Science Research Papers**

[![Python Version](https://img.shields.io/badge/Python-3.13-blue.svg)](https://www.python.org/)
[![Status](https://img.shields.io/badge/Status-Active-brightgreen.svg)](https://github.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Last Updated](https://img.shields.io/badge/Updated-2026-blue.svg)]()

## Overview

MatExtractAI is an **end-to-end intelligent system** that transforms unstructured **materials science research PDFs** into **structured, evidence-backed JSON** using a combination of deterministic parsing and local LLM-based agents.

With a focus on **scientific rigor, traceability, and reproducibility**, MatExtractAI is purpose-built for:
- Research data repositories
- Automated research pipelines  
- Materials informatics platforms
- Cross-paper meta-analysis



## Key Features

| Feature | Description |
|---------|-------------|
| **Intelligent PDF Processing** | Page-wise extraction with automatic section segmentation (Intro, Methods, Results, etc.) |
| **Table Intelligence** | Reliable extraction, cleaning, and validation of research tables |
| **Domain-Specific Agents** | 4 specialized LLM agents for mechanical properties, composition, processing, & microstructure |
| **Evidence Validation** | All extracted claims linked to exact textual evidence with confidence scoring |
| **100% Offline** | Uses local LLMs via Ollama - no cloud dependencies, complete data privacy |
| **Cross-Agent Verification** | Consistency checks between multiple agents for enhanced accuracy |
| **Scientific Rigor** | Deterministic parsing + semantic validation for reproducible results |


## System Architecture

MatExtractAI employs a **dual-pipeline approach** for extraction and validation:

### Pipeline A ‚Äî Extraction & Structuring
A deterministic multi-stage pipeline that converts PDFs into structured JSON:

```
Research PDF 
    ‚Üì
[1] PDF Ingestion & Page Extraction
    ‚Üì
[2] Text Normalization & Page-wise Processing
    ‚Üì
[3] Automatic Section Segmentation
    ‚Üì
[4] Table Detection & Extraction
    ‚Üì
[5] Domain-Specific Agent Processing
    ‚îú‚îÄ‚Üí Mechanical Properties Agent
    ‚îú‚îÄ‚Üí Alloy Composition Agent
    ‚îú‚îÄ‚Üí Processing Routes Agent
    ‚îî‚îÄ‚Üí Microstructure Agent
    ‚Üì
[6] Structured JSON Output
```

### Pipeline B ‚Äî Validation & Trust Scoring
Applies rigorous validation logic to ensure scientific accuracy:

```
Extracted JSON
    ‚Üì
[7] Evidence Extraction & Linking
    ‚Üì
[8] Numeric Range Validation
    ‚Üì
[9] Semantic Consistency Analysis
    ‚Üì
[10] Cross-Agent Agreement Scoring
    ‚Üì
Final Output with Confidence Metrics
```  


## üìÇ Project Structure

```
MatExtractAI/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/                      # Core source code
‚îÇ   ‚îú‚îÄ‚îÄ agents/                  # üß† LLM extraction agents (composition, mechanics, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/              # ‚úÖ Validation & confidence scoring logic
‚îÇ   ‚îú‚îÄ‚îÄ ingest/                  # üì• PDF ingestion & preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ utils/                   # üîß Shared utilities & helpers
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # ‚ö° Pipeline A entrypoint
‚îÇ   ‚îî‚îÄ‚îÄ run_pipeline_b.py        # üîç Pipeline B validation runner
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îî‚îÄ‚îÄ raw_pdfs/                # üìÑ Input research papers (PDF format)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ output/                   # üìä Generated structured outputs
‚îÇ   ‚îú‚îÄ‚îÄ *_page_text.json         # Raw text extraction
‚îÇ   ‚îú‚îÄ‚îÄ *_sections.json          # Section segmentation
‚îÇ   ‚îú‚îÄ‚îÄ *_tables.json            # Table extraction
‚îÇ   ‚îú‚îÄ‚îÄ *_*_agent.json           # Agent-specific extractions
‚îÇ   ‚îú‚îÄ‚îÄ *_evaluated.json         # Pipeline B validation results
‚îÇ   ‚îî‚îÄ‚îÄ *.csv                    # Cleaned table exports
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt             # üì¶ Python dependencies
‚îú‚îÄ‚îÄ README.md                    # üìñ This file
‚îî‚îÄ‚îÄ .gitignore                   # üö´ Git ignores
```


## Example Output

**Input:** Research PDF on magnesium alloy processing  
**Output:** Structured, validated material property data

```json
{
  "alloy_name": "AZ31",
  "composition": {
    "Al": "3%",
    "Zn": "1%",
    "evidence": "Table 1, page 2"
  },
  "avg_grain_size_um": 15,
  "grain_size_evidence": "SEM analysis, Section 3.2",
  "texture": "strong basal texture",
  "processing_route": "hot rolling followed by annealing",
  "mechanical_properties": {
    "yield_strength_MPa": 85,
    "ultimate_tensile_strength_MPa": 235
  },
  "final_confidence": "high",
  "agent_agreements": {
    "composition_agent": "confirmed",
    "microstructure_agent": "confirmed",
    "mechanics_agent": "confirmed"
  }
}
```

**Key insight:** Every extracted value is **linked to evidence** with transparency scores from multiple validation agents.

## Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Language** | Python 3.13+ | Core implementation |
| **PDF Processing** | PyMuPDF (fitz) | Fast, reliable text extraction |
| **Table Extraction** | Camelot-py | Intelligent table detection & parsing |
| **Pattern Matching** | regex | Deterministic section/entity parsing |
| **LLM Inference** | Ollama | Local, private LLM execution |
| **Data Processing** | pandas, numpy | Validation & numerical analysis |
| **Orchestration** | Python asyncio | Parallel agent execution |

> **System Requirements:**
> - Python 3.13+
> - ‚ö†Ô∏è Ghostscript (required by Camelot for advanced table extraction)
> - Ollama installed with LLM models loaded locally

## ‚ñ∂Ô∏è Quick Start Guide

### Prerequisites
- Python 3.13 installed
- Ollama running locally with LLM models loaded
- Ghostscript installed (for table extraction)

### Installation & Execution

#### 1Ô∏è. Clone & Setup Virtual Environment
```bash
git clone https://github.com/your-org/MatExtractAI.git
cd MatExtractAI

# Create virtual environment
python -m venv .venv

# Activate it
# On Windows:
.venv\Scripts\activate
# On macOS/Linux:
source .venv/bin/activate
```

#### 2Ô∏è. Install Dependencies
```bash
pip install -r requirements.txt
```

#### 3Ô∏è. Prepare Input Data
Place your PDF files in the `data/raw_pdfs/` directory:
```bash
cp your_research_paper.pdf data/raw_pdfs/
```

#### 4. Run Pipeline A (Extraction)
```bash
python src/main.py
```
This generates structured JSON files in `output/`

#### 5Ô∏è. Run Pipeline B (Validation)
```bash
python src/run_pipeline_b.py
```
This adds confidence scores and validation metrics to your extracted data

### Output Files
- `*_page_text.json` ‚Äî Raw extracted text by page
- `*_sections.json` ‚Äî Auto-segmented document sections
- `*_tables.json` ‚Äî Extracted table data
- `*_agent.json` ‚Äî Agent-specific extractions
- `*_evaluated.json` ‚Äî Final validated output with confidence scores
- `*.csv` ‚Äî Cleaned table exports

## Why MatExtractAI?

| Challenge | Traditional LLMs | MatExtractAI |
|-----------|------------------|--------------|
| **Accuracy** | ‚ùå Prone to hallucination | ‚úÖ Evidence-backed, validated |
| **Traceability** | ‚ùå Black-box outputs | ‚úÖ All claims linked to source |
| **Privacy** | ‚ùå Cloud-dependent | ‚úÖ 100% local & offline |
| **Reproducibility** | ‚ùå Non-deterministic | ‚úÖ Deterministic parsing + validation |
| **Domain Knowledge** | ‚ùå Generic LLMs | ‚úÖ Materials science specialists |
| **Cost** | ‚ùå API/subscription fees | ‚úÖ One-time setup, zero runtime costs |
| **Confidence Scoring** | ‚ùå Not available | ‚úÖ Detailed metrics from cross-validation |  


## Documentation

- [Architecture Details](docs/ARCHITECTURE.md) ‚Äî Deep dive into pipeline design
- [Agent Guide](docs/AGENTS.md) ‚Äî How to customize extraction agents
- [API Reference](docs/API.md) ‚Äî Integration guide
- [Examples](examples/) ‚Äî Sample workflows and use cases

## Future Work

- **Multi-paper Aggregation** ‚Äî Consolidate data across multiple papers
- **Knowledge Graph Export** ‚Äî RDF/OWL format for semantic integration
- **Dataset-Level Validation** ‚Äî Cross-dataset consistency analysis
- **Web Dashboard** ‚Äî Interactive visualization & export interface
- **Chemistry & Physics Support** ‚Äî Extend beyond materials science
- **REST API** ‚Äî Scalable inference service
- **Collaborative Curation** ‚Äî Community feedback loop for model improvement


## Author & Contact

**Amaljosh Maadhav J**

- Email: [amal018josephmathi@gmail.com]
- LinkedIn: [https://www.linkedin.com/in/amaljoshmaadhavj/]
- GitHub: [https://github.com/amaljoshmaadhavj]